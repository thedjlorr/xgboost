{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Python Models to Predict Auto Loan Default\n",
    "\n",
    "- XGBoost:  Serialize with Pickle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, shutil # used to create necessary folders\n",
    "import pickle\n",
    "import sklearn\n",
    "from xgboost import XGBClassifier \n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>BAD</th>\n",
       "      <th>LOAN</th>\n",
       "      <th>LOANDUE</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>REASON</th>\n",
       "      <th>JOB</th>\n",
       "      <th>YOJ</th>\n",
       "      <th>DEROG</th>\n",
       "      <th>DELINQ</th>\n",
       "      <th>CLAGE</th>\n",
       "      <th>NINQ</th>\n",
       "      <th>CLNO</th>\n",
       "      <th>DEBTINC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>772418</td>\n",
       "      <td>1</td>\n",
       "      <td>1100</td>\n",
       "      <td>25860.0000</td>\n",
       "      <td>39025.000000</td>\n",
       "      <td>CarImp</td>\n",
       "      <td>Other</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.366667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>33.779915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>477724</td>\n",
       "      <td>1</td>\n",
       "      <td>1300</td>\n",
       "      <td>70053.0000</td>\n",
       "      <td>68400.000000</td>\n",
       "      <td>CarImp</td>\n",
       "      <td>Other</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>121.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>33.779915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150746</td>\n",
       "      <td>1</td>\n",
       "      <td>1500</td>\n",
       "      <td>13500.0000</td>\n",
       "      <td>16700.000000</td>\n",
       "      <td>CarImp</td>\n",
       "      <td>Other</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>149.466667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>33.779915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108584</td>\n",
       "      <td>1</td>\n",
       "      <td>1500</td>\n",
       "      <td>73760.8172</td>\n",
       "      <td>101776.048741</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.922268</td>\n",
       "      <td>0.25457</td>\n",
       "      <td>0.449442</td>\n",
       "      <td>179.766275</td>\n",
       "      <td>1.186055</td>\n",
       "      <td>21.296096</td>\n",
       "      <td>33.779915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321534</td>\n",
       "      <td>0</td>\n",
       "      <td>1700</td>\n",
       "      <td>97800.0000</td>\n",
       "      <td>112000.000000</td>\n",
       "      <td>CarImp</td>\n",
       "      <td>Office</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>93.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>33.779915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5955</th>\n",
       "      <td>346389</td>\n",
       "      <td>0</td>\n",
       "      <td>88900</td>\n",
       "      <td>57264.0000</td>\n",
       "      <td>90185.000000</td>\n",
       "      <td>DebtCon</td>\n",
       "      <td>Other</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>221.808718</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>36.112347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5956</th>\n",
       "      <td>255372</td>\n",
       "      <td>0</td>\n",
       "      <td>89000</td>\n",
       "      <td>54576.0000</td>\n",
       "      <td>92937.000000</td>\n",
       "      <td>DebtCon</td>\n",
       "      <td>Other</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>208.692070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>35.859971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5957</th>\n",
       "      <td>668928</td>\n",
       "      <td>0</td>\n",
       "      <td>89200</td>\n",
       "      <td>54045.0000</td>\n",
       "      <td>92924.000000</td>\n",
       "      <td>DebtCon</td>\n",
       "      <td>Other</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>212.279697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>35.556590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5958</th>\n",
       "      <td>233047</td>\n",
       "      <td>0</td>\n",
       "      <td>89800</td>\n",
       "      <td>50370.0000</td>\n",
       "      <td>91861.000000</td>\n",
       "      <td>DebtCon</td>\n",
       "      <td>Other</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>213.892709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>34.340882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5959</th>\n",
       "      <td>462288</td>\n",
       "      <td>0</td>\n",
       "      <td>89900</td>\n",
       "      <td>48811.0000</td>\n",
       "      <td>88934.000000</td>\n",
       "      <td>DebtCon</td>\n",
       "      <td>Other</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>219.601002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>34.571519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5960 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Loan_ID  BAD   LOAN     LOANDUE          VALUE   REASON     JOB  \\\n",
       "0      772418    1   1100  25860.0000   39025.000000   CarImp   Other   \n",
       "1      477724    1   1300  70053.0000   68400.000000   CarImp   Other   \n",
       "2      150746    1   1500  13500.0000   16700.000000   CarImp   Other   \n",
       "3      108584    1   1500  73760.8172  101776.048741      NaN     NaN   \n",
       "4      321534    0   1700  97800.0000  112000.000000   CarImp  Office   \n",
       "...       ...  ...    ...         ...            ...      ...     ...   \n",
       "5955   346389    0  88900  57264.0000   90185.000000  DebtCon   Other   \n",
       "5956   255372    0  89000  54576.0000   92937.000000  DebtCon   Other   \n",
       "5957   668928    0  89200  54045.0000   92924.000000  DebtCon   Other   \n",
       "5958   233047    0  89800  50370.0000   91861.000000  DebtCon   Other   \n",
       "5959   462288    0  89900  48811.0000   88934.000000  DebtCon   Other   \n",
       "\n",
       "            YOJ    DEROG    DELINQ       CLAGE      NINQ       CLNO    DEBTINC  \n",
       "0     10.500000  0.00000  0.000000   94.366667  1.000000   9.000000  33.779915  \n",
       "1      7.000000  0.00000  2.000000  121.833333  0.000000  14.000000  33.779915  \n",
       "2      4.000000  0.00000  0.000000  149.466667  1.000000  10.000000  33.779915  \n",
       "3      8.922268  0.25457  0.449442  179.766275  1.186055  21.296096  33.779915  \n",
       "4      3.000000  0.00000  0.000000   93.333333  0.000000  14.000000  33.779915  \n",
       "...         ...      ...       ...         ...       ...        ...        ...  \n",
       "5955  16.000000  0.00000  0.000000  221.808718  0.000000  16.000000  36.112347  \n",
       "5956  16.000000  0.00000  0.000000  208.692070  0.000000  15.000000  35.859971  \n",
       "5957  15.000000  0.00000  0.000000  212.279697  0.000000  15.000000  35.556590  \n",
       "5958  14.000000  0.00000  0.000000  213.892709  0.000000  16.000000  34.340882  \n",
       "5959  15.000000  0.00000  0.000000  219.601002  0.000000  16.000000  34.571519  \n",
       "\n",
       "[5960 rows x 14 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto = pd.read_csv('Data_orig/AutoLoan.csv')\n",
    "\n",
    "auto.fillna(pickle.load(open('/sasinside/userdata/gegrab/resources/hmeq/autoloan_impute.pickle', 'rb')),inplace=True)\n",
    "\n",
    "auto\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID      int64\n",
       "BAD          int64\n",
       "LOAN         int64\n",
       "LOANDUE    float64\n",
       "VALUE      float64\n",
       "REASON      object\n",
       "JOB         object\n",
       "YOJ        float64\n",
       "DEROG      float64\n",
       "DELINQ     float64\n",
       "CLAGE      float64\n",
       "NINQ       float64\n",
       "CLNO       float64\n",
       "DEBTINC    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "target         = [\"BAD\"]\n",
    "numeric_inputs = ['LOAN', 'LOANDUE', 'VALUE', 'YOJ', 'DEROG', 'DELINQ', 'CLAGE', 'NINQ','CLNO', 'DEBTINC']\n",
    "class_inputs   = ['REASON', 'JOB']\n",
    " \n",
    "auto           =auto.dropna()\n",
    "auto.REASON.replace(np.NaN,'CarImp',regex = True, inplace=True)\n",
    "auto.JOB.replace(np.nan,'Other',regex = True, inplace=True)\n",
    "\n",
    " \n",
    "x              = auto.drop(['BAD', 'Loan_ID'], axis=1)\n",
    "y              = auto[target].astype(\"category\")\n",
    "\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write out 5 test records\n",
    "auto2 =auto.head()\n",
    "auto2.drop(['BAD'], axis=1, inplace=True)\n",
    "auto2.to_csv('Data_orig/autoloan2_ds2_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset Into Training and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (3875, 12)\n",
      "test size: (1661, 12)\n",
      "train sample\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into training set and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1) # 70% training and 30% test\n",
    "\n",
    "print(\"train size: \" + str(x_train.shape))\n",
    "print(\"test size: \" + str(x_test.shape))\n",
    "print(\"train sample\")\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom preprocessing for categorical inputs to use in XGB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3875, 18)\n",
      "(1661, 18)\n"
     ]
    }
   ],
   "source": [
    " \n",
    "ohe = OneHotEncoder(sparse = False, handle_unknown=\"ignore\")\n",
    "enc = ohe.fit_transform(x_train[class_inputs])\n",
    "enc2 = ohe.transform(x_test[class_inputs])\n",
    "\n",
    " \n",
    "x_train[ohe.get_feature_names(class_inputs)] = pd.DataFrame(enc, index=x_train.index)\n",
    "x_train.drop(class_inputs,1,inplace=True)\n",
    "\n",
    "x_test[ohe.get_feature_names(class_inputs)] = pd.DataFrame(enc2, index=x_test.index)\n",
    "x_test.drop(class_inputs,1,inplace=True)\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickle the one hot encoding\n",
    "pickle.dump(ohe, open('/sasinside/userdata/gegrab/resources/hmeq/autoloan_encoder_lorry.pickle', 'wb'))\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:39:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:39:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "booster = xgb.XGBClassifier(max_depth=3,\n",
    "                        booster='dart',\n",
    "                        eta=0.3,\n",
    "                        silent=1,\n",
    "                        n_estimators=100)\n",
    "\n",
    "\n",
    "# Train XGBoost Classifer\n",
    "booster.fit(x_train,y_train)\n",
    "\n",
    "modelName = \"AutoLoan_XGBoost_Lorry\"\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle the trained XGB Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(model, open(project_dir+\"/HMEQ_XGB.pickle\", 'wb'))\n",
    "pickle.dump(booster, open(\"/sasinside/userdata/gegrab/resources/hmeq\"+\"/\"+ modelName + \".pickle\", 'wb'))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Out Parameters for Copying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Loan_ID\", \"BAD\", \"LOAN\", \"LOANDUE\", \"VALUE\", \"REASON\", \"JOB\", \"YOJ\", \"DEROG\", \"DELINQ\", \"CLAGE\", \"NINQ\", \"CLNO\", \"DEBTINC\"\n",
      "\n",
      "Loan_ID, BAD, LOAN, LOANDUE, VALUE, REASON, JOB, YOJ, DEROG, DELINQ, CLAGE, NINQ, CLNO, DEBTINC\n"
     ]
    }
   ],
   "source": [
    "# Define input variables and perform formatting to match with score code file\n",
    "\n",
    "input_params = ''\n",
    "for col in auto.columns:\n",
    "    input_params += col\n",
    "    if col != auto.columns[-1]:\n",
    "        input_params += ', '\n",
    "\n",
    "input_cols = ''\n",
    "for col in auto.columns:\n",
    "    input_cols += \"\\\"\" + col + \"\\\"\"\n",
    "    if col != auto.columns[-1]:\n",
    "        input_cols += ', '\n",
    "\n",
    "\n",
    "print(input_cols)\n",
    "print(\"\")\n",
    "print(input_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test XGBoost Score Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreXGB(Loan_ID, LOAN, LOANDUE, VALUE, REASON, JOB, YOJ, DEROG, DELINQ, CLAGE, NINQ, CLNO, DEBTINC):\n",
    "    \"Output: P_BAD\"\n",
    "        \n",
    "    \n",
    "    import pickle\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    inputArray = pd.DataFrame([[Loan_ID, LOAN, LOANDUE, VALUE, REASON, JOB, YOJ, DEROG, DELINQ, CLAGE, NINQ, CLNO, DEBTINC]],\n",
    "                              columns = [\"Loan_ID\", \"LOAN\", \"LOANDUE\", \"VALUE\", \"REASON\", \"JOB\", \"YOJ\", \"DEROG\", \"DELINQ\", \"CLAGE\", \"NINQ\", \"CLNO\", \"DEBTINC\"]\n",
    "                               )\n",
    " \n",
    "\n",
    "    def preprocessing(df, ohe_loc = None):\n",
    "\n",
    "        categorical_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "    \n",
    "        with open(ohe_loc, \"rb\") as ohe_file:\n",
    "            ohe = pickle.load(ohe_file) \n",
    "        \n",
    "        enc = ohe.transform(df[categorical_cols])\n",
    "    \n",
    "        df[ohe.get_feature_names(categorical_cols).tolist()] = pd.DataFrame(enc, index=df.index)\n",
    "\n",
    "        df.drop(categorical_cols,1,inplace=True)\n",
    "\n",
    "        df.dropna(inplace=True)\n",
    "    \n",
    "        return df\n",
    "\n",
    "    \n",
    "    \n",
    "    inputArray.REASON.replace(np.nan,'HomeImp',regex = True, inplace=True)\n",
    "    inputArray.JOB.replace(np.nan,'Other',regex = True, inplace=True)\n",
    "    \n",
    "    inputArray.drop(['Loan_ID'], axis=1, inplace=True)\n",
    "    test_data = preprocessing(inputArray, \"/sasinside/userdata/gegrab/resources/hmeq/autoloan_encoder_lorry.pickle\")\n",
    "      \n",
    "     \n",
    "    sess = pickle.load(open(\"/sasinside/userdata/gegrab/resources/hmeq/AutoLoan_XGBoost_Lorry.pickle\", 'rb'))\n",
    "\n",
    "    P_BAD = float(sess.predict_proba(test_data)[0,0])\n",
    "    \n",
    "    \n",
    "     \n",
    "    \n",
    "     \n",
    "     \n",
    "    return (P_BAD)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01895761489868164\n",
      "0.20398783683776855\n",
      "0.00891488790512085\n",
      "0.5066103935241699\n",
      "0.20350873470306396\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_test2 = pd.read_csv('Data_orig/autoloan2_ds2_test.csv') \n",
    "  \n",
    " \n",
    "for i in range(5):\n",
    "    print(scoreXGB(**X_test2.iloc[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Out XGBoost Score Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_code = \"\"\"\n",
    "def scoreXGB(Loan_ID, LOAN, LOANDUE, VALUE, REASON, JOB, YOJ, DEROG, DELINQ, CLAGE, NINQ, CLNO, DEBTINC):\n",
    "    \"Output: P_BAD\"\n",
    "        \n",
    "    \n",
    "    import pickle\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    inputArray = pd.DataFrame([[Loan_ID, LOAN, LOANDUE, VALUE, REASON, JOB, YOJ, DEROG, DELINQ, CLAGE, NINQ, CLNO, DEBTINC]],\n",
    "                              columns = [\"Loan_ID\", \"LOAN\", \"LOANDUE\", \"VALUE\", \"REASON\", \"JOB\", \"YOJ\", \"DEROG\", \"DELINQ\", \"CLAGE\", \"NINQ\", \"CLNO\", \"DEBTINC\"]\n",
    "                               )\n",
    " \n",
    "\n",
    "    def preprocessing(df, ohe_loc = None):\n",
    "\n",
    "        categorical_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "    \n",
    "        with open(ohe_loc, \"rb\") as ohe_file:\n",
    "            ohe = pickle.load(ohe_file) \n",
    "        \n",
    "        enc = ohe.transform(df[categorical_cols])\n",
    "    \n",
    "        df[ohe.get_feature_names(categorical_cols).tolist()] = pd.DataFrame(enc, index=df.index)\n",
    "\n",
    "        df.drop(categorical_cols,1,inplace=True)\n",
    "\n",
    "        df.dropna(inplace=True)\n",
    "    \n",
    "        return df\n",
    "\n",
    "    \n",
    "    \n",
    "    inputArray.REASON.replace(np.nan,'HomeImp',regex = True, inplace=True)\n",
    "    inputArray.JOB.replace(np.nan,'Other',regex = True, inplace=True)\n",
    "    \n",
    "    inputArray.drop(['Loan_ID'], axis=1, inplace=True)\n",
    "    test_data = preprocessing(inputArray, \"/sasinside/userdata/gegrab/resources/hmeq/autoloan_encoder_lorry.pickle\")\n",
    "      \n",
    "     \n",
    "    sess = pickle.load(open(\"/sasinside/userdata/gegrab/resources/hmeq/AutoLoan_XGBoost_Lorry.pickle\", 'rb'))\n",
    "\n",
    "    P_BAD = float(sess.predict_proba(test_data)[0,0])\n",
    "    \n",
    "    \n",
    "     \n",
    "    \n",
    "     \n",
    "     \n",
    "    return (P_BAD)\"\"\"\n",
    "\n",
    "\n",
    "f = open('Data_orig/AutoLoan_XGB_Lorry.py',\"w+\")\n",
    "f.write(score_code)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 2022 Latest",
   "language": "python",
   "name": "pytorch2021"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
